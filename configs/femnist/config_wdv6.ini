[general]
tbpath=./tblogs_femnist_ADAM/femnist_r56_dgc_cr0.6
# max 3560 clients
nodes=500

[dgc] # deep-gradient-compression
dgc=True
compress_ratio = 0.6
#[0.25,0.0225,0.015625,0.004,0.001]
momentum = 0.9
momentum_correction=True

[gf] # global fusion
global_fusion=False
fusing_ratio=[0.9,0.8,0.6,0.4,0.0]
# [0.0,0.4,0.6,0.8,0.9]
global_fusion_after_warmup=True

[trainer]
# [small_femnist, resnet9_femnist, resnet18_femnist, resnet50_femnist, resnet101_femnist,
# resnet56_femnist_gdc, resnet110_femnist_gdc, net_femnist_afo]
model=resnet56_femnist_gdc
max_iteration=160
device=GPU
dataset_path=./data/femnist
dataset_type=niid
# batchsize in local client
local_bs=10
# ep in local client
local_ep=1
frac=0.2

# warmup learning loss
start_lr=0.0001
max_lr=0.001
min_lr=0.0000001
base_step=10
end_step=155


optimizer=GFDGCSGD
lossfun=crossentropy
# SGD: dgc setting {"momentum": 0.9,"nesterov": True,"weight_decay": 1e-4}
optimizer_args = {"momentum": 0.9,"nesterov": True,"weight_decay": 1e-4}

[aggregator]
# ["SGD", "ADAGRAD", "ADAM", "YOGI"]
optimizer=ADAM
# SGD: default {"momentum": 0,"nesterov": False,"weight_decay": 0}
# optimizer_args =  {"momentum": 0,"nesterov": False,"weight_decay": 0}

# ADAM: default {"betas":(0.9, 0.999), "eps":1e-08, "weight_decay":0, "amsgrad":False}
optimizer_args =  {"betas":(0.9, 0.999), "eps":1e-3, "weight_decay":0, "amsgrad":False}

# YOGI: default {"betas":(0.9, 0.999), "eps":1e-08, "weight_decay":0, "amsgrad":False}
# optimizer_args =  {"betas": (0.9, 0.999),"eps": 1e-3,"initial_accumulator": 1e-6, "weight_decay": 0}

[eval]
output=result.jpg
title=BCFL(niid)
